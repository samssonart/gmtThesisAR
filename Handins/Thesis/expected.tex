%!TEX root = ../main.tex

 The aim of the method is to produce plausible lighting for Augmented Reality applications, and thus increase the sense of realism of the composed graphics. The experiments are designed to evaluate the similarity of a real object and a virtual representation of the same object in the same controlled lighting conditions.
\section{Setup}
We chose a particular object with a rich variety of materials, in this case it was an Xbox 360 controller with a custom paint job. We modified a 3D model of the same Xbox 360 controller to match the custom paint job and the materials were replicated as closely as possible to the real object using Unity's built-in shaders. In the end 4 main shaders were used, a highly reflective plastic for the borders and some of the buttons, a more matte plastic for the main body, a completely specular chrome for the Xbox button and a semi-transparent and glossy plastic for the colored buttons. The choice of this motif was based both on the ease to find a reliable 3D counterpart for a real object and on the already wide variety of materials present in the object.\newline
In order to provide a ground truth for a reliable side-by-side comparison, we take a screen capture of the application running while both the real and virtual object are in the frame, in similar positions and orientations and affected by controlled lighting that is also simulated using the method for the virtual counterpart. Another experiment is a direct substitution: place the marker on the table, then place the real controller on the marker in a similar position and orientation. This provides a clear comparison, everything in the scene remains the same, and both the real and virtual objects can be appreciated in the same setting.\newline
As for benchmarking, how our method stands in comparison to other similar ones, we replicate the conditions of the experiments presented in the results section for the methods by \citet{kanbara2004}, \citet{karsh2014} and \citet{pessoa2011} in terms of similar setting and virtual objects used. The resulting images are compared to the ones from their respective methods. In order to replicate these settings additional 3D models are needed, namely a teapot and the dragon and Buddha from the Stanford 3D Scanning Repository.\newline
The actual way in which the experiment is conducted is defined in the following scenario:
\begin{itemize}
    \item \textbf{Setting:} A room with consistent and invariable lighting is used and some kind of flat, matte surface to lay the objects on. An Xbox 360 controller with the characteristics described previously and a marker to track the virtual object.
    \item \textbf{Requirements:} A mobile device running the developed demo application, a marker for virtual objects. A real object and its corresponding virtual counterpart, modelled as close as possible. Common 3D models from the Stanford 3D Scanning Repository.
    \item \textbf{Goals:} Obtaining a set of images that will enable readers and experimenters alike to make a fair comparison of the method application, side by side with a real object counterpart.
    \item \textbf{Actions:} Place the controller on the surface, and capture and image. Then remove the real controller and substitute it with the marker in a way that the virtual controller appears in the most similar position and orientation possible; capture an image in the end as well. Replicate the scenarios in \citet{kanbara2004}, \citet{karsh2014} and \citet{pessoa2011} using teapots, Buddahs and dragons and capture images of each.
     \item \textbf{Benchmark:} We capture the image result yielded by our method, as well as the time per frame and use them for comparison's sake and benchmarking, head to head with the results from similar methods.
\end{itemize}

It's important to also mention the need of replicating the previous work's settings and the reason why. In some cases the product is not a runtime application, and thus the only applicable comparison is image-based. The authors of other runtime methods were approached to evaluate the possibility of using their binaries to produce images and they either declined or gave no answer. And so the only possible comparison is image to image and taking their word for the performance indications in the form of frames per second.\newline
All of the experiments were recorded on video by connecting the tablet device to a laptop, and are available to watch. The images shown here are select still images from said videos and the framerates discussed per experiment are averages from the on-screen counter seen on each video. It's also important to say that the recorded framerates are about 10\% lower than when the application is not being recorded.\newline

\section{Experiment 1: Real object substitution}

This experiment produced satisfactory results, the materials and the position and orientation on the virtual object are not exactly the same, and so the highlights shining off the surface are not in the same relative places. But the shadow shows that the light is placed in an acceptable approximation of the real light position. The application is running at 24 FPS on this screen capture and it's a good measure of the average of performance. 
\begin{figure}[H]
    \centering
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{Figures/ContReal.png} % first figure itself
        \caption{Real custom painted Xbox 360 controller}
    \end{minipage}\hfill
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{Figures/ContVirtual.png} % second figure itself
        \caption{Virtual counterpart of the same object}
    \end{minipage}
\end{figure}

\section{Experiment 2: Karsch's scenario }
This scenario was hard to replicate, due to the unusual framing and placing of the objects. The method we are comparing to is not a runtime method, but even so there are conclusions that can be drawn. In the image produced by the \citet{karsh2014} application it's hard to say if the lighting in the real and virtual components of the image really corresponds. The light sources, except for one, are not present in the frame and there are no similar real objects to the virtual ones that would serve as ground truth. Our results show enough evidence that the lighting in both the real and virtual worlds is similar, with cues such as the presence of real objects and their shadow directions.\newline
The framerate of our application for this experiment is 15 FPS on average. It is still acceptable considering that there are 6 virtual dense models.
\begin{figure}[H]
    \centering
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{Figures/budaDragonKarsch.png} % first figure itself
        \caption{Karsch's method results}
    \end{minipage}\hfill
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{Figures/budaDragon.png} % second figure itself
        \caption{This methods's results}
    \end{minipage}
\end{figure}

\section{Experiment 3: Kanbara and Pessoa's scenarios} 
These two scenarios will be grouped together due to the fact that the steps to replicate the experiment are the same. They both presented ceramic material teapots with a lighting setting that they did not specify. 
\begin{figure}[H]
    \centering
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{Figures/Pessoa.png} % first figure itself
        \caption{Pessoa's method results}
    \end{minipage}\hfill
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{Figures/kanbara.png} % first figure itself
        \caption{Kanbara's method results}
    \end{minipage}\hfill
\end{figure}

Both results look well blended into the environment, however in Pessoa's case it also must be said that the lighting setting is not disclosed and is not obvious from just looking at the results. For the aforementioned method there's also a considerable amount of pre-production required for the method to actually work, and the performance has a rather bad scaling, ranging from 180 FPS with no objects to 5 FPS with seven objects. Our method doesn't have those problems, and performance scales better going from 24 FPS with a single object to 15 with six of them.\newline
In the case of Kanbara's results, they scene looks good, but the downsides to their method that ours resolves are the need for a physical 3D marker to probe lighting and the performance, they report 20 FPS on a computer for the experiment they published. It's admittedly a more than 10 year old computer at the time of this writing, but our method is achieving slightly better framerates on a mobile device.\newline
\begin{figure}[H]
    \centering
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{Figures/pessoaComp.png} % first figure itself
        \caption{Pessoa's comparison results}
    \end{minipage}\hfill
    \begin{minipage}{0.475\textwidth}
        \centering
        \includegraphics[width=0.99\textwidth]{Figures/KanbaraComp.png} % first figure itself
        \caption{Kanbara's comparison results}
    \end{minipage}\hfill
\end{figure}

\section{Gallery}
Here are a few more screen captures from the application that show the potential of the method for the reader to draw their own conclusions.
\begin{figure}[H]
    \centering
    \begin{minipage}{0.38\textwidth}
        \centering
        \includegraphics[width=1.5\textwidth]{Figures/ContBoth.png} % first figure itself
    \end{minipage}\hfill
    \begin{minipage}{0.38\textwidth}
        \centering
        \includegraphics[width=1.5\textwidth]{Figures/Lena1.png} % second figure itself
    \end{minipage}\hfill
        \begin{minipage}{0.38\textwidth}
        \centering
        \includegraphics[width=1.5\textwidth]{Figures/TeapotVirtual.png} % second figure itself
    \end{minipage}\hfill
    \begin{minipage}{0.38\textwidth}
        \centering
        \includegraphics[width=1.5\textwidth]{Figures/TeapotReal.png} % first figure itself
    \end{minipage}
\end{figure}
%!TEX root = ../main.tex
Augmented Reality is a technology with a lot of potential, but in its current state it's not very attractive to end-consumers. Having to point a device's camera for extended periods of time is uncomfortable and makes it hard to engage in using AR applications, but the way the virtual objects are rendered is completely unrealistic, which makes many AR applications unattractive to end users as well.
The rendering of virtual objects on current AR applications has a number of shortcomings in the state of the art: marker jiggle, inaccurate depth cues, lack of occlusion from real life objects and incompatible lighting.\newline
The method that we propose addresses the latter problem. The method is based on the idea that a $360^{\circ}$  photograph of the environment can give us a lot of information about the lighting conditions, and that such $360^{\circ}$  panoramic photographs are now simple to create locally on an average mobile device. \newline
We present a method that automatically infers the lighting from a scene, and shades virtual objects accordingly. The environment-aware lighting is applied at runtime, and so it produces more realistic imagery regardless of the AR tracking technology used.\newline
 Unlike previous works, we focus on mobile devices, utilizing the ease of creating $360^{\circ}$ imagery in practice. This decision comes by noting that AR is better suited for mobile devices than computers given their ease of mobility and the ready available sensors they have at the developer's disposal.\newline
The major research question we investigate is: "Can the accuracy of lighting in AR applications be improved by using a mobile device to its full potential?". What this means is that thanks to the many ways a smartphone or tablet can interact with the user and the environment, we can know a lot about the surroundings. Such information is useful to save computation time.\newline
The main contributions of our method are:
\begin{itemize}
    \item An image-based method with which the lighting conditions of the entire environment are approximated.
    \item The seamless integration of virtual objects by the emulation of shading and shadows from acquired light sources.
\end{itemize}
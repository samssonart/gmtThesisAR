%!TEX root = ../main.tex
Augmented Reality is a technology with a lot of potential, but in its current state it's not very attractive to end-consumers. While there are usability concerns that have an impact, the way the virtual objects are rendered is completely unrealistic, and that probably also impacts end-user's willingness to try AR applications.
The rendering of virtual objects on current AR applications has a number of shortcomings in the state of the art. There are many factors that come into play and give away the lack of feasibility of an AR object: marker jiggle, inaccurate depth cues, lack of occlusion from real life objects and incompatible lighting.
The method proposed in this work addresses the latter problem. The method is based on the idea that a $360^{\circ}$  photograph of the environment can give us a lot of information about the lighting conditions, and that such $360^{\circ}$  panoramic photographs are now simple to create locally on an average mobile device. \newline
The method's output is a a correctly augmented image where the lighting information calculated from the panoramic image is taken into account in the shading and shadowing. The environment-aware lighting is applied at runtime, and so it produces more feasible imagery regardless of the AR tracking technology used.\newline
It's important to stress the fact that the method is proposed for mobile devices. Unlike previous works, we focus on mobile devices, utilizing the ease of creating $360^{\circ}$ imagery in practice. This decision comes from the ease of producing the $360^{\circ}$  photographs locally, from the judgement that AR is better suited for mobile devices than computers (for mobility and ease of use reasons) and also to be able to exploit the devices geolocation hardware.\newline
The major research question we investigate is: "Can the accuracy of lighting in AR applications be improved by using a mobile device to its full potential?". What this means is that thanks to the many ways a smartphone or tablet can interact with the user and the environment we can know a lot about the surroundings. Such information could potentially be useful to save computation time, which will make up for the lower computational capabilities while comparing favorably against other methods.\newline
The main contributions of our method are:
\begin{itemize}
    \item An image-based method with which the lighting conditions of the entire environment are approximated.
    \item Produce imagery that seamlessly integrate virtual objects by emulating shading and shadows from acquired light sources.
\end{itemize}